{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "from sklearn import preprocessing\n",
    "import time\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def log_loss(p, y):\n",
    "    return (-y * np.log(p) - (1 - y) * np.log(1 - p))\n",
    "\n",
    "def grad_log_loss(p, y, x):\n",
    "    return (p - y) * x\n",
    "\n",
    "def mod_log_loss(p, y_priv, p_RR):\n",
    "    p_mod = p_RR *  p + (1 - p_RR) * (1 - p) \n",
    "    return log_loss(p_mod, y_priv)\n",
    "\n",
    "def grad_mod_log_loss(p, y_priv, p_RR, x):\n",
    "    p_mod = p_RR *  p + (1 - p_RR) * (1 - p) \n",
    "    return (p * (1 - p) * (1 - 2 * p_RR) / (p_mod - (1 - y_priv))) * x\n",
    "\n",
    "def priv_log_loss(p, y_priv, p_RR):\n",
    "    p1 = p_RR *  np.log(p) - (1 - p_RR) * np.log(1 - p) \n",
    "    p0 = p_RR *  np.log(1 - p) - (1 - p_RR) * np.log(p) \n",
    "    return (- y_priv * p1 - (1 - y_priv) * p0)   \n",
    "\n",
    "def grad_priv_log_loss(p, y_priv, p_RR, x):\n",
    "    return (p_RR * (p - y_priv) - (1 - p_RR) * (p - (1 - y_priv))) * x\n",
    "\n",
    "def update_weight(weight, learning_rate, gradient, maxNorm):\n",
    "    weightUpd = weight - learning_rate * gradient\n",
    "    weightProj = weightUpd/np.maximum(1, np.linalg.norm(weightUpd, 2)/maxNorm)\n",
    "    return weightProj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "d = 5\n",
    "thetaStar = np.random.randn(d)\n",
    "B = np.linalg.norm(thetaStar, 2)\n",
    "Epsilon = np.array([0.1, 0.5, 1], dtype=float)\n",
    "delta = 0.001\n",
    "N = np.array([1000, 2000, 4000, 6000, 8000, 10000], dtype=int)\n",
    "num_iter = 100\n",
    "thetaInit = np.zeros(d)\n",
    "lamda = 0.01\n",
    "SigmaInit = lamda * np.eye(d)\n",
    "etaInit = 1\n",
    "\n",
    "errorL2 = np.zeros([len(Epsilon), len(N), num_iter])\n",
    "errorL2_priv = np.zeros([len(Epsilon), len(N), num_iter])\n",
    "errorL2_obj = np.zeros([len(Epsilon), len(N), num_iter])\n",
    "for e in range(len(Epsilon)):\n",
    "    eps = Epsilon[e]\n",
    "    for n in range(len(N)):\n",
    "        num_data = N[n]\n",
    "        for iter in range(num_iter): \n",
    "            X = np.zeros([num_data, d])\n",
    "            Y = np.zeros(num_data)\n",
    "            pStar = np.zeros(num_data)\n",
    "            for i in range(num_data):\n",
    "                Phi1 = np.random.randn(d)\n",
    "                Phi0 = np.random.randn(d)\n",
    "                X[i,:] = Phi1 - Phi0\n",
    "                pStar[i] = sigmoid(np.dot(thetaStar, X[i,:]))\n",
    "                Y[i] = np.random.binomial(1, pStar[i])\n",
    "            L = np.amax(np.linalg.norm(X, axis = 1))\n",
    "            sigma = L * np.sqrt(np.log(1/delta))/(eps*np.sqrt(num_data))\n",
    "            Sigma = SigmaInit\n",
    "\n",
    "            theta = thetaInit\n",
    "            theta_priv = thetaInit\n",
    "            theta_obj = thetaInit\n",
    "            for i in range(num_data):\n",
    "                eta = etaInit\n",
    "                x = X[i,:]\n",
    "                Sigma = Sigma + np.outer(x, x)\n",
    "                y = Y[i]\n",
    "                p_RR = sigmoid(eps)\n",
    "                toss = np.random.binomial(1, p_RR)\n",
    "                if toss == 1:\n",
    "                    y_priv = y\n",
    "                else:\n",
    "                    y_priv = 1 - y\n",
    "                p = sigmoid(np.dot(x, theta))\n",
    "                grad = grad_log_loss(p, y, x)\n",
    "                theta = update_weight(theta, eta, grad, B)    \n",
    "                \n",
    "                p_priv = sigmoid(np.dot(x, theta_priv))\n",
    "                grad_priv = grad_priv_log_loss(p_priv, y_priv, p_RR, x)\n",
    "                theta_priv = update_weight(theta_priv, eta, grad_priv, B)\n",
    "\n",
    "                p_obj = sigmoid(np.dot(x, theta_obj))\n",
    "                grad_obj = grad_log_loss(p_obj, y, x) + np.random.normal(0, sigma, d)\n",
    "                theta_obj = update_weight(theta_obj, eta, grad_obj, B)\n",
    "\n",
    "            errorL2[e, n, iter] = np.linalg.norm(theta - thetaStar, 2) / np.sqrt(num_data)\n",
    "            errorL2_priv[e, n, iter] = np.linalg.norm(theta_priv - thetaStar, 2) / np.sqrt(num_data)\n",
    "            errorL2_obj[e, n, iter] = np.linalg.norm(theta_obj - thetaStar, 2) / np.sqrt(num_data)\n",
    "\n",
    "            print(\"Training time:\" + str(time.time() - start_time) + \" seconds\")\n",
    "            print(\"Learning rate: {}\\nIteration: {}\".format(0.01, iter))\n",
    "\n",
    "errorL2_avg = np.mean(errorL2,axis=2)\n",
    "errorL2_priv_avg = np.mean(errorL2_priv,axis=2)\n",
    "errorL2_obj_avg = np.mean(errorL2_obj,axis=2)\n",
    "\n",
    "errorL2_std = np.std(errorL2,axis=2)\n",
    "errorL2_priv_std = np.std(errorL2_priv,axis=2)\n",
    "errorL2_obj_std = np.std(errorL2_obj,axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = os.path.join(\".\", \"plots\") # Directory to save plots\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "for e in range(len(Epsilon)):\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.errorbar(N, errorL2_avg[e,:], errorL2_std[e,:], label='MLE (Non-private)')\n",
    "    plt.errorbar(N, errorL2_priv_avg[e,:], errorL2_priv_std[e,:], label='RR (Local model)')\n",
    "    plt.errorbar(N, errorL2_obj_avg[e,:], errorL2_obj_std[e,:], label='Obj (Central model)')\n",
    "\n",
    "    plt.xlabel(\"Number of Samples\")\n",
    "    plt.ylabel(\"Estimation Error in L2-norm\") \n",
    "    plt.legend(loc= 'best', fontsize=12)\n",
    "    plt.grid(True)\n",
    "\n",
    "    eps = Epsilon[e]\n",
    "    fig_name = \"L2_norm_\" + str(eps) + \".pdf\"\n",
    "    fname = os.path.join(plot_dir, fig_name)\n",
    "    plt.savefig(fname, format = \"pdf\", dpi = 1200, bbox_inches=\"tight\")\n",
    "\n",
    "    print('Error of MLE :', errorL2_avg[e,:])\n",
    "    print('Error of RR :', errorL2_priv_avg[e,:])\n",
    "    print('Error of Obj :', errorL2_obj_avg[e,:])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
